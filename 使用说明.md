# GraphGen Enhanced 完整流程使用说明

## 概述

本项目实现了从故障案例文本到高质量预训练数据的完整流程：
1. **数据生成** - 从原始文本提取知识图谱并生成预训练数据
2. **数据去重** - 使用MinHash算法去除重复内容
3. **质量检测** - 检测生成内容是否存在幻觉
4. **数据过滤** - 根据质量评估结果过滤数据，只保留高质量数据

## 快速开始

### 1. 环境准备

```bash
# 安装依赖
pip install -r requirements.txt

# 配置API密钥（在config.py中）
DEEPSEEK_API_KEY = "your_api_key_here"
```

### 2. 执行完整流程

```bash
# 运行单个案例完整流程
python complete_pipeline.py

# 运行批量处理（避免文件冲突）
python batch_pipeline_enhanced.py
```

### 3. 自定义案例处理

```python
import asyncio
from complete_pipeline import CompletePipeline

async def process_custom_case():
    # 创建流程实例
    pipeline = CompletePipeline()
    
    # 准备故障案例（原始文本可以简略）
    fault_text = """某局升级后忙音播放有问题，SPD单板上加载的忙音有问题。
    忙音是异步音，该问题一般是异步音有问题造成的，可以先查看一下SPD单板上是否已经加载该语音，
    如果没有加载，需要按照正确流程加载该语音，如果已经加载，需要重新加载该语音。"""
    
    # 执行完整流程
    result = await pipeline.run_complete_pipeline(fault_text, "CUSTOM_CASE_001")
    
    # 查看结果
    print(f"总耗时: {result['final_results']['total_time']:.2f}秒")
    print(f"实体数量: {result['final_results']['generation_stats']['entities']}")
    print(f"质量评分: {result['final_results']['quality_score']:.2f}")

# 运行
asyncio.run(process_custom_case())
```

## 流程详解

### 步骤1: 数据生成
- **输入**: 故障案例原始文本
- **处理**: 
  - 使用LLM提取实体和关系
  - 构建知识图谱
  - 生成多种格式的预训练数据
- **输出**: 
  - `{case_id}_knowledge_graph.json` - 知识图谱
  - `{case_id}_pretrain_knowledge.json` - 预训练数据
  - `{case_id}_complete_results.json` - 完整结果

### 步骤2: 数据去重
- **输入**: `{case_id}_complete_results.json`
- **处理**: 
  - 使用MinHash算法计算相似度
  - 移除相似度超过阈值的重复内容
- **输出**: 
  - `pretrain_data_deduplicated/pure_texts.txt` - 去重后的纯文本
  - `pretrain_data_deduplicated/qa_pairs.jsonl` - 去重后的问答对
  - `pretrain_data_deduplicated/structured_texts.jsonl` - 去重后的结构化文本

### 步骤3: 质量检测
- **输入**: 原始文本 + 生成的预训练文本
- **处理**: 
  - 对比原始内容和生成内容
  - 检测是否存在幻觉
  - 计算一致性评分
- **输出**: 质量评分和幻觉检测结果

### 步骤4: 数据过滤
- **输入**: 生成的数据 + 质量评估结果
- **处理**: 
  - 根据质量阈值过滤数据
  - 移除未通过质量评估的数据
  - 保留高质量数据
- **输出**: 过滤后的高质量数据

## 输出文件说明

### 单个案例处理文件
- `data/{case_id}_key_results.json` - 关键结果（包含所有重要信息）
  - 处理摘要：各步骤耗时统计
  - 质量评估：评分和检测结果
  - 生成统计：实体和关系统计
  - 去重统计：去重效果统计
  - 最终数据：知识图谱和预训练数据
- `data/{case_id}_high_quality_data.json` - 高质量数据（仅通过质量评估时生成）
  - 质量评分
  - 知识图谱
  - 预训练数据

### 批量处理文件（避免冲突）
- `data/batch_processing_results_{timestamp}.json` - 批量处理结果
- `data/{batch_id}_{case_id}_key_results.json` - 每个案例的关键结果
- `data/{batch_id}_{case_id}_high_quality_data.json` - 每个案例的高质量数据（仅通过质量评估时生成）
- `pretrain_data_deduplicated_{batch_id}_{case_id}/` - 每个案例的去重数据目录

### 去重后数据
- `pretrain_data_deduplicated_{case_id}/pure_texts.txt` - 纯文本数据
- `pretrain_data_deduplicated_{case_id}/qa_pairs.jsonl` - 问答对数据
- `pretrain_data_deduplicated_{case_id}/structured_texts.jsonl` - 结构化数据
- `pretrain_data_deduplicated_{case_id}/processing_stats.json` - 处理统计

## 配置参数

### 去重参数
- `similarity_threshold = 0.5` - 相似度阈值（0-1之间）

### 质量检测参数
- 在 `huanjue/config.py` 中配置检测参数

### 数据过滤参数
- `min_overall_score = 0.7` - 最低总体评分
- `min_consistency_score = 0.6` - 最低一致性评分
- `allow_hallucination = False` - 是否允许幻觉

### 文件保存策略
- `save_strategy = "minimal"` - 保存策略（minimal: 最少文件, detailed: 详细文件）
- `save_key_results = True` - 保存关键结果文件
- `save_high_quality_only = True` - 仅保存高质量数据文件
- `save_deduplication_data = True` - 保存去重数据
- `save_processing_logs = True` - 保存处理日志

## 注意事项

1. **原始文本要求**: 故障案例文本应包含问题描述、处理过程、解决方案等关键信息
2. **API限制**: 确保DeepSeek API密钥有效且有足够配额
3. **文件路径**: 确保 `data/` 目录存在且有写入权限
4. **内存使用**: 处理大量数据时注意内存使用情况
5. **文件冲突**: 批量处理时使用 `batch_pipeline_enhanced.py` 避免文件覆盖
6. **批次管理**: 每个批次都有唯一的批次ID，便于管理和追踪

## 故障排除

### 常见问题
1. **API调用失败**: 检查API密钥和网络连接
2. **文件不存在**: 确保输入文件路径正确
3. **内存不足**: 减少批量处理的数据量

### 日志查看
- 查看 `logs/graphgen_enhanced.log` 获取详细错误信息
